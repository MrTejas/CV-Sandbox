{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c492b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "#neural net imports\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ceb1aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import external libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import math\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57854cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on : cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "print('Running on :',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d4e8243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 60000\n",
      "Test set size: 10000\n"
     ]
    }
   ],
   "source": [
    "# definind transform for the MNIST dataset\n",
    "# converting to tensors and normalize pixel vals with mean 0.5 and std-deviation 0.5\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=(0.5), std=(0.5))\n",
    "])\n",
    "\n",
    "# Download and load the train set\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test set\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"Training set size:\", len(trainset))\n",
    "print(\"Test set size:\", len(testset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0609c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displays the details of 1 keypoint and its descriptor\n",
    "def print_keypoint_details(keypoint, descriptor):\n",
    "    print('pt : ',keypoint.pt)\n",
    "    print('size : ',keypoint.size)\n",
    "    print('angle : ',keypoint.angle)\n",
    "    print('response : ',keypoint.response)\n",
    "    print('octave : ', keypoint.octave)\n",
    "    print('class id : ',keypoint.class_id)\n",
    "    print('----------------------------------')\n",
    "    print('descriptor : ',descriptor)\n",
    "\n",
    "# Function to extract SIFT features from an image\n",
    "def extract_sift_features(image):\n",
    "    gray = image.numpy().squeeze().astype(np.uint8)  # Convert to CV_8U (needed for passing to sift function)\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    # print(print_keypoint_details(keypoints[0],descriptors[0]))\n",
    "    return descriptors\n",
    "\n",
    "# Function to extract SIFT features from a set of images\n",
    "def extract_features(data_loader):\n",
    "    features = []\n",
    "    for images, _ in data_loader:\n",
    "        for image in images:\n",
    "            descriptors = extract_sift_features(image)\n",
    "            if descriptors is not None:\n",
    "                features.extend(descriptors)\n",
    "    return np.array(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9fe9df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = extract_features(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e15dda3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   0.   0.   2.  73.   1.   0.   0.  62.   0.   0.  17. 183.   4.\n",
      "   0.   6. 183.   1.   0.   2.  34.   1.   0.  26.  46.   1.   0.   0.\n",
      "   0.   0.   0.   2.   0.   0.   0.   0.  86.   8.   0.   0.  70.   5.\n",
      "   0.   4. 183.  61.   9.  13. 183.  40.   0.   1.  34.  10.   9.  49.\n",
      "  48.   7.   0.   0.   0.   0.   0.   2.   0.   0.   0.   0.  28.  20.\n",
      "   0.   0.  11.   1.   0.   0. 116. 183.  93.  26. 116.   9.   0.   0.\n",
      "   6.  27.  76. 107.  18.   2.   0.   0.   0.   0.   0.   2.   0.   0.\n",
      "   0.   0.   0.   2.   0.   0.   0.   0.   0.   0.   0.  16.  10.   0.\n",
      "   0.   0.   0.   0.   0.   2.   5.   1.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "print(train_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f606af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
